#!/usr/bin/env python3

import argparse
import enum
import shutil
import sys
import unicodedata
from copy import copy
from dataclasses import dataclass
from pathlib import Path
from typing import Iterator, TextIO


# HELP "./findt <path> <contents...>; search for text <contents> in <path> (dir or file)

class Colours(enum.Enum):
    RED = "\033[31m"
    GRN = "\033[32m"
    CLR = "\033[0m"

    def offset(self, s) -> int:
        if self.value in s:
            count = s.count(self.value)
            return len(self.value) * count
        return 0


class UTF8Table:
    V_BORDER = "│"
    H_BORDER = "─"
    L_JUNCTION = "├"
    R_JUNCTION = "┤"
    TL_BORDER = "┌"
    TR_BORDER = "┐"
    BL_BORDER = "└"
    BR_BORDER = "┘"

    def __init__(self):
        self.width, self.height = shutil.get_terminal_size()

    @staticmethod
    def _colour_offset(s: str) -> int:
        offset = Colours.RED.offset(s)
        offset += Colours.GRN.offset(s)
        offset += Colours.CLR.offset(s)
        return offset

    def header(self, string) -> str:
        assert "\n" not in string
        offset = self._colour_offset(string)
        str_width = self.width - 2
        string = string[:str_width + offset]
        top_section = f"{UTF8Table.TL_BORDER}{UTF8Table.H_BORDER * (self.width - 2)}{UTF8Table.TR_BORDER}"
        mid_section = f"{UTF8Table.V_BORDER}{string:<{str_width + offset}}{UTF8Table.V_BORDER}{Colours.CLR.value}"
        bot_junction = f"{UTF8Table.L_JUNCTION}{UTF8Table.H_BORDER * (self.width - 2)}{UTF8Table.R_JUNCTION}"
        return "\n".join([top_section, mid_section, bot_junction])

    def row(self, string) -> str:
        offset = self._colour_offset(string)
        str_width = self.width + offset - 2
        string = string[:str_width]
        return f"{UTF8Table.V_BORDER}{string:<{str_width}}{UTF8Table.V_BORDER}"

    def end(self) -> str:
        return f"{UTF8Table.BL_BORDER}{UTF8Table.H_BORDER * (self.width - 2)}{UTF8Table.BR_BORDER}"


# https://stackoverflow.com/a/518232
def normalize(string, normalized=False) -> str:
    if not normalized:
        return string
    return "".join(c for c in unicodedata.normalize("NFD", string) if unicodedata.category(c) != "Mn")


def upper(string, uppercase=False) -> str:
    if not uppercase:
        return string
    return string.upper()


def merge_intervals(intervals):
    # sort intervals by start time
    intervals.sort(key=lambda x: x[0])

    merged = []
    for interval in intervals:
        # If the list of merged intervals is empty or if the current interval does not overlap with the previous, append it to merged
        if not merged or merged[-1][1] < interval[0]:
            merged.append(interval)
        else:
            # Otherwise, there is overlap, so we merge the current and previous intervals
            merged[-1][1] = max(merged[-1][1], interval[1])

    return merged


@dataclass
class Block:
    owner: Path
    _query: str
    _query_uppercase: bool
    _query_normalized: bool

    before: list[str]
    exact_match_lc: int
    exact_match: str
    after: list[str]

    @property
    def rank(self) -> int:
        return self.exact_match_lc + 1

    def lines(self) -> Iterator[tuple[int, str]]:
        block_lc = self.rank - len(self.before)
        for bline in self.before:
            yield block_lc, bline
            block_lc += 1

        yield block_lc, self.exact_match
        block_lc += 1

        for aline in self.after:
            yield block_lc, aline
            block_lc += 1

        return


class Aggregate:
    def __init__(self, owner: Path, padding: int):
        self.__owner: Path = owner
        self.__padding: int = padding
        self.__pqueries: list[str] = []
        self.__lines: dict[int, str] = {}
        self.__matched_lines: list[int] = []
        self.__start_lc: int = 9999999
        self.__end_lc: int = -1

    def aggregate(self, blocks: list[Block]) -> None:
        blocks = sorted(blocks, key=lambda b: b.rank)
        for b in blocks:
            self.__matched_lines.append(b.rank)
            self.__pqueries.append(b._query)
            for line_count, line in b.lines():
                self.__start_lc = min(line_count, self.__start_lc)
                self.__end_lc = max(line_count, self.__end_lc)
                if line_count in self.__lines:
                    continue
                self.__lines[line_count] = line

    def ppretty(self, highlighted: bool = False) -> Iterator[str]:
        max_lc_padding = len(str(self.__end_lc))

        def decorate(lc, line) -> str:
            if not highlighted or lc not in self.__matched_lines:
                return line

            def region_range(t: tuple[int]) -> int:
                return t[-1] - t[0]

            # we want to match all processed queries against our string
            #  for all matches, suppose the following:
            #  content line
            #       ^      *
            #  ^     *
            #    ^ *
            #  this is an overlapping regions issue
            #  these are some sample indices (st, end):
            #  (1, 5), (3, 7), (4, 6), (10, 15). . .
            #  this should be simplified to:
            #  (1, 7), (10, 15)
            #  a sane way to solve this issue would be, starting from the
            #  earliest region (sorted by [0]):
            #  for every region start, check if it's under our max
            #  if it is, we overlap, and we should extend our end to theirs, and pop it
            #  if it isn't, continue
            #  fortunately, this is a solved problem and google carried me, so
            #  I don't have to waste my time here
            pline = self.__lines[lc]
            areas: list[list[int]] = []
            for q in self.__pqueries:
                if q in pline:
                    start = pline.index(q)
                    end = start + len(q)
                    areas.append([start, end])
            areas = merge_intervals(areas)
            # noinspection PyTypeChecker
            biggest_area = sorted(areas, key=region_range)[-1]
            start = biggest_area[0]
            end = biggest_area[1]
            return f"{line[:start]}{Colours.RED.value}{line[start:end]}{Colours.CLR.value}{line[end:]}"

        def is_sequential(old_k, new_k) -> bool:
            return old_k + 1 == new_k

        def build(lc: int, line: str) -> str:
            return f"{format(lc, str(max_lc_padding) + 'd')}: {decorate(lc, line)}"

        int_to_str = str if not highlighted else lambda i: f"{Colours.GRN.value}{i}{Colours.CLR.value}"
        header_content = f" ".join(list(map(int_to_str, sorted(self.__matched_lines))))
        yield f"{self.__owner} lines~{self.__padding}: {header_content}"

        for k in sorted(self.__lines.keys()):
            yield build(k, self.__lines[k])

        return


def match_blocks(file: Path,
                 queries: list[str],
                 padding: int = 2,
                 normalized: bool = False,
                 uppercase: bool = False) -> Iterator[Block]:
    def insert(q: list, e: object, padding: int = padding) -> None:
        assert len(q) <= padding
        if len(q) >= padding:
            # remove the oldest element (if we're using .append)
            q.pop(0)
        q.append(e)

    def advance(f: TextIO) -> Iterator[tuple[int, str]]:
        tell = f.tell()
        while True:
            line = upper(normalize(f.readline().rstrip(), normalized=normalized), uppercase=uppercase)
            yield tell, line
            previous_tell = tell
            tell = f.tell()
            if tell == previous_tell:
                return

    def peek(f: TextIO, pc: int) -> list[str]:
        """
        :param f: fhandle
        :param pc: peek count
        """
        tell = f.tell()
        try:
            lines = []
            advance_iterator = advance(f)
            for i in range(pc):
                _, line = next(advance_iterator)
                lines.append(line)
                itell = f.tell()
                if tell == itell:
                    return lines
            return lines
        finally:
            f.seek(tell)

    def drive(f: TextIO, padding: int = padding) -> Iterator[Block]:
        lc = 0
        before = []
        for tell, line in advance(f):
            truthy_query_results = []
            for query in queries:
                query = upper(normalize(query, normalized=normalized), uppercase=uppercase)
                if query in line:
                    truthy_query_results.append(query)

            yield from map(
                lambda query: Block(
                    owner=file,
                    _query=query,
                    _query_uppercase=uppercase,
                    _query_normalized=normalized,
                    before=copy(before),
                    after=peek(f, padding),
                    exact_match=line,
                    exact_match_lc=lc
                ),
                truthy_query_results
            )
            insert(before, line)
            lc += 1
        return

    assert file.exists()
    try:
        with open(file, "r") as fhandle:
            yield from drive(fhandle, padding=padding)
    except UnicodeDecodeError:
        pass  # silently skip undecodeable files


def preprocess(directory: Path) -> list[Path]:
    """
    Find all files from the directory provided, and return their path.
    If the path provided is a file, it will return itself.
    :returns: list of absolute files, that exist
    """
    if directory is None:
        raise ValueError("dir null not permitted")
    if not directory.exists():
        return []
    if directory.is_file():
        return [directory]
    # block devices etc. check
    if not directory.is_dir():
        return []
    return list(
        filter(
            lambda p: p.is_file(),
            map(
                lambda p: p,
                [Path(p) for p in directory.rglob("*")]
            )
        )
    )


def main(options):
    padding = options.padding
    uppercase = options.insensitive
    normalized = options.normalized
    decorated = options.decorated
    highlighted = options.highlighted
    multimatches: dict[str, list[Block]] = {}
    paths = preprocess(Path(options.path))
    for p in paths:
        matched_blocks = match_blocks(
            p,
            queries=options.filters,
            padding=padding,
            normalized=normalized,
            uppercase=uppercase
        )

        key = str(p)
        try:
            for block in matched_blocks:
                if key not in multimatches:
                    multimatches[key] = [block]
                    continue
                multimatches[key].append(block)
        except PermissionError:
            print(f"Permission denied to read {key}!", file=sys.stderr)

    for k, v in multimatches.items():
        aggregate = Aggregate(Path(k), padding)
        aggregate.aggregate(v)
        if not decorated:
            for entry in aggregate.ppretty(highlighted=highlighted):
                print(entry)

        if decorated:
            ppretty = aggregate.ppretty(highlighted=highlighted)
            header = next(ppretty)
            table = UTF8Table()
            print(table.header(header))
            for table_entry in ppretty:
                print(table.row(table_entry))
            print(table.end())


@dataclass
class UserOptions:
    path: str
    filters: list[str]
    # -i, --insensitive
    insensitive: bool
    normalized: bool
    # --padding <int>
    padding: int
    # --no-highlight is the inverse of this value
    highlighted: bool
    # --no-decorations is the inverse of this value
    decorated: bool


def _parse_args(args) -> UserOptions:
    parser = argparse.ArgumentParser(description="findt: a recursive content text locator")
    parser.add_argument("path", type=str)
    parser.add_argument("filters", nargs="+")
    parser.add_argument("-i", "--insensitive", default=False, action="store_true")
    parser.add_argument("-m", "--no-highlights", default=False, action="store_true")
    parser.add_argument("-d", "--no-decorations", default=False, action="store_true")
    parser.add_argument("--padding", type=int, default=2, required=False)
    options = parser.parse_args(args)
    return UserOptions(
        path=options.path,
        filters=options.filters,
        insensitive=options.insensitive,
        normalized=options.insensitive,
        padding=options.padding,
        highlighted=not options.no_highlights,
        decorated=not options.no_decorations
    )


if __name__ == "__main__":
    main(_parse_args(sys.argv[1:]))
